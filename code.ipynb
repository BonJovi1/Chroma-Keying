{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment-0\n",
    "### Done by: Abhinav Gupta, 20171059\n",
    "\n",
    "Objectives:\n",
    "- Kickstarter to the Computer Vision course, Spring 2020\n",
    "- Getting acquainted with OpenCV\n",
    "- Playing and experimenting with simple computer vision tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first import all the libraries that we'd need. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from collections import Counter \n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Converting Videos to its constituent Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We convert a given video to its constituent images, and save the output to a folder. \n",
    "- If you want to use a video that's already stored on your computer, then we use `cv2.VideoCapture(path_to_video)`\n",
    "- Here we use `cv2.VideoCapture(0)`, so that we can use the computer's webcam to record a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We first create a VideoCapture object, and pass zero as a parameter, indicating that we want to record a video using the webcam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-db56681f3031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create a VideoCapture object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# 0 for webcam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a VideoCapture object \n",
    "# 0 for webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "\n",
    "if (cap.isOpened()== False): \n",
    "  print(\"Error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `cv2.imshow` pops open the webcam recording, and you can dance/sing while you're being recorded.\n",
    "- `cv2.imwrite` wrties each image frame into the 'frames' directory. \n",
    "- The loop continues unless we quit by pressing 'q'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while(cap.isOpened()):\n",
    "  # Capture frame-by-frame\n",
    "  ret, frame = cap.read()\n",
    "  \n",
    "  if ret == True:\n",
    "    name = './frames/frame' + str(count) + '.jpg'\n",
    "    print ('Creating...' + name) \n",
    "    cv2.imwrite(name, frame)\n",
    "#     cv2.imshow('Frame', frame)\n",
    "    count+=1\n",
    "\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "      break\n",
    " \n",
    "  # Break the loop\n",
    "  else: \n",
    "    break\n",
    " \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So finally, we've got ourselves a folder 'frames' which contains the constituent images of the video. \n",
    "- For the first question of the assignment, I used a video that was already stored on my machine. \n",
    "- For the second part, I changed the parameter of VideoCapture as already explained, and recorded a video in real time. That was fun :D\n",
    "- Here is the link to all the frames that we get from the video:\n",
    "https://drive.google.com/drive/folders/1p1iUfXoh8hSsDOgtgJOxOkm9fvPGfZqR?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem-2: Getting a video from a sequence of images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now, let's go the other way around! \n",
    "- We've already got a sequence of images in 'frames' folder. Let's take all the images in that folder and put them in a list called `images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'frames'\n",
    "video_name = 'video.avi'\n",
    "\n",
    "name1 = './frames/frame' + str(0) + '.jpg'\n",
    "frame = cv2.imread(name1)\n",
    "height, width, layers = frame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For creating a video, we are going to use OpenCV's `VideoWriter` function. \n",
    "- One of the parameters needed is the width and height of the images. \n",
    "- So let's takes the first image - `image[0]` and compute its width and height. \n",
    "- And then instantiate the `video` object using `cv2.VideoWriter`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoWriter(video_name, 0, 13, (width,height))\n",
    "# images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Awesome! Now let's iterate through all the images and append them to the video object created! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,83):\n",
    "    finalname = './frames/frame' + str(i) + '.jpg'\n",
    "    video.write(cv2.imread(finalname))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And Voila! We've got ourselves a video, created from using a sequence of images! \n",
    "- We can control the 'frames per second' or the fps of the video, which is the third parameter in the `cv2.VideoWriter` function. The function itself takes 4 paramters - video file name, encoding, fps, and the (width & height).\n",
    "- I have taken fps = 10 for the above case. We can speed up the video by increasing the fps. \n",
    "- Here's the link: https://drive.google.com/file/d/1oNvTddCaYrW9GCLv6gYaVyWFmPqEzGS_/view?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem-3: Chroma Keying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- And finally, we come to the most interesting part of the assignment! \n",
    "- We implement the technique of 'Chroma Keying'! \n",
    "- We use two videos for the same, one as the foreground and one as the background. \n",
    "- The foreground video is one with a green screen, and coins are falling from the top. \n",
    "https://drive.google.com/file/d/1u_JouXoO0LY6gjZai9psr2w5BjBSosex/view?usp=sharing\n",
    "- The background video is me, playing the guitar xD \n",
    "https://drive.google.com/file/d/1RUhF_nHe27NE9nKMEEyeTAP0zBxLova0/view?usp=sharing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, let's break down both the videos into their constituent image frames and store them in folders 'final1' and 'final2'\n",
    "- This is highly similar to the problem above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_video = './green.mp4'\n",
    "b_video = './captain.mov'\n",
    "\n",
    "f_vidcap = cv2.VideoCapture(f_video)\n",
    "b_vidcap = cv2.VideoCapture(b_video)\n",
    "\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We've got the VideoCapture objects, now let's break them down into frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while f_vidcap.isOpened() and b_vidcap.isOpened(): \n",
    "    f_success, f_image = f_vidcap.read()\n",
    "    if f_success == True:\n",
    "        name = './final1/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(name, f_image)\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "    b_success,b_image = b_vidcap.read()\n",
    "    if b_success == True:\n",
    "        name = './final2/' + str(count) + '.jpg'\n",
    "        cv2.imwrite(name, b_image)\n",
    "    count+=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now that we have 467 images of both, foreground and background, let's take any one foreground image and try to retrieve the 'green screen' from it, that is, get the pixel values of the background. \n",
    "- The 'color' function takes an image, finds the pixel value that is most frequently occurring in the image and returns it. \n",
    "- Since our image has a pretty consistent green background, we can assure that the pixel value it returns would be the one belonging to the green components of the image! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color(image):\n",
    "    img = cv2.imread(image)\n",
    "    d = img.shape\n",
    "    a = []\n",
    "\n",
    "    for i in range(0, d[0]):\n",
    "        for j in range(0, d[1]):\n",
    "            a.append(tuple(np.array(img[i,j,:])))\n",
    "\n",
    "    f = tuple(a)\n",
    "\n",
    "    most_common,num_most_common = Counter(f).most_common(1)[0]\n",
    "\n",
    "    return most_common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = color('./final1/1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 251, 15)\n"
     ]
    }
   ],
   "source": [
    "print(check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Hence, the pixel values are: (5,251,15) - which is a nice version of green colour! Now I need to take my image and make it the background, thereby replacing the green screen! \n",
    "- So we merge the two images - and the green screen is replace by my guitar!\n",
    "- This is exactly what the 'mergeImage' function below does. It takes 2 images and return the merged one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeImage(fg, bg):\n",
    "    a = check\n",
    "    d2 = bg.shape\n",
    "    \n",
    "    for i in range(0, d2[0]):\n",
    "        for j in range(0, d2[1]):\n",
    "            if fg[i,j,2] < a[2]+10 and fg[i,j,2] > a[2]-10 and fg[i,j,1] > a[1]-10 and fg[i,j,1] < a[1]+10 and fg[i,j,0] < a[0]+10 and fg[i,j,0] > a[0]-10:\n",
    "                fg[i,j] = bg[i,j]\n",
    "                \n",
    "    return fg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now we've already got our foreground and background images in final1 and final2. Let's iterate through them, take images from them simultaneously and pass them to the merge function. \n",
    "- The final merged image is stored in the folder 'final3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1_folder = 'final1'\n",
    "image2_folder = 'final2'\n",
    "\n",
    "for i in range(0,467):\n",
    "    name1 = './final1/' + str(i) + '.jpg'\n",
    "    name2 = './final2/' + str(i) + '.jpg'\n",
    "    img1 = cv2.imread(name1)\n",
    "    img2 = cv2.imread(name2)\n",
    "    \n",
    "    img = mergeImage(img1, img2)\n",
    "    name = './final3/' + str(i) + '.jpg' \n",
    "    cv2.imwrite(name, img)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now all our images are in the 'final3' folder. \n",
    "- All that's left now is to take those images and form a video, just like we did in Problem-2! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here's an example of how the merged image looks like: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![example](./merged-image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let;s convert the merged images into a video!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = 'final3'\n",
    "video_name = 'video2.avi'\n",
    "\n",
    "name1 = './final3/' + str(0) + '.jpg'\n",
    "frame = cv2.imread(name1)\n",
    "height, width, layers = frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoWriter(video_name, 0, 13, (width,height))\n",
    "# images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "\n",
    "for i in range(0,73):\n",
    "    finalname = './final3/' + str(i) + '.jpg'\n",
    "    video.write(cv2.imread(finalname))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sorry, I'm running out of time, so I've only done it for 73 frames! Here's the link to the video: \n",
    "https://drive.google.com/file/d/1S3QMBBUSlD6kBaUzMVKnfFdM71xrIfmk/view?usp=sharing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
